{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Dynamic Range Quantization (동적 범위 양자화)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_model_dir = 'saved_model/'\n",
    "\n",
    "# TFLite Converter 생성\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir)\n",
    "\n",
    "# 동적 범위 양자화 설정\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "\n",
    "# TFLite 모델로 변환\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# 변환된 모델 저장\n",
    "with open('quantized_model/yamnet_dynamic_quant.tflite', 'wb') as f:\n",
    "    f.write(tflite_model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Full Integer Quantization (정수 양자화)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_model_dir = 'saved_model/'\n",
    "\n",
    "# TFLite Converter 생성\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir)\n",
    "\n",
    "# 정수 양자화 설정\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "\n",
    "# 훈련 또는 추가 데이터 없이 바로 정수 양자화 진행\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "\n",
    "# 모든 텐서를 8비트 정수로 변환\n",
    "converter.inference_input_type = tf.uint8\n",
    "converter.inference_output_type = tf.uint8\n",
    "\n",
    "# TFLite 모델로 변환\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# 변환된 모델 저장\n",
    "with open('quantized_model/yamnet_full_integer_quant.tflite', 'wb') as f:\n",
    "    f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Float16 Quantization (FP16 양자화)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_model_dir = 'saved_model/'\n",
    "\n",
    "# TFLite Converter 생성\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir)\n",
    "\n",
    "# FP16 양자화 설정\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.target_spec.supported_types = [tf.float16]\n",
    "\n",
    "# TFLite 모델로 변환\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# 변환된 모델 저장\n",
    "with open('quantized_model/yamnet_fp16_quant.tflite', 'wb') as f:\n",
    "    f.write(tflite_model)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
