{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\jspark\\miniconda3\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division, print_function\n",
    "\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import resampy\n",
    "import soundfile as sf\n",
    "import tensorflow as tf\n",
    "from tf_keras import Model, layers\n",
    "\n",
    "\n",
    "import params as yamnet_params\n",
    "import yamnet as yamnet_model\n",
    "import features as features_lib\n",
    "\n",
    "import librosa\n",
    "import json\n",
    "import glob\n",
    "import os\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "print(physical_devices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "intense = {\"약함\" : 0.,\"보통\":1.,\"강함\":2.}\n",
    "emotion_enc = {\"기쁨\" : 0, \"사랑스러움\" : 1, \"두려움\" : 2, \"화남\" : 3, \"슬픔\" : 4, \"놀라움\" : 5, \"없음\" : 6}\n",
    "emotion_dec = { 0 : \"기쁨\", 1 : \"사랑스러움\", 2 : \"두려움\", 3 : \"화남\", 4 : \"슬픔\", 5 : \"놀라움\", 6 : \"없음\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = yamnet_params.Params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_segments_from_json(paths, wav_prefix):\n",
    "    for path in paths:\n",
    "        with open(path, 'r') as f:\n",
    "            data = json.load(f)\n",
    "        sr = int(data['Wav']['SamplingRate'])\n",
    "        tmp_prefix = os.path.join(wav_prefix, \"실내\" if \"실내\" in path else \"실외\")\n",
    "        wav_name = os.path.join(tmp_prefix, data['File']['FileName'] + \".wav\")\n",
    "        audio, _ = librosa.load(wav_name, sr=sr)\n",
    "        audio_resampled = librosa.resample(audio, orig_sr=sr, target_sr=16000)\n",
    "        #y_emotion_class = []\n",
    "        #y_emotion_intensity = []\n",
    "        #audios = []\n",
    "\n",
    "        for entry in data['Conversation']:\n",
    "            start_time = float(entry['StartTime'].replace(\",\",\"\"))\n",
    "            end_time = float(entry['EndTime'].replace(\",\",\"\"))\n",
    "            emotion_category = emotion_enc[entry['VerifyEmotionTarget']]\n",
    "            emotion_intense = intense[entry['VerifyEmotionLevel']]\n",
    "            start_sample = int(start_time * 16000)\n",
    "            end_sample = int(end_time * 16000)\n",
    "            audio_segment = audio_resampled[start_sample:end_sample]\n",
    "\n",
    "            #audios.append(np.array(audio_segments))\n",
    "            #y_emotion_class.append(emotion_category)\n",
    "            #y_emotion_intensity.append(emotion_level)\n",
    "\n",
    "            yield np.array(audio_segment), emotion_category, emotion_intense\n",
    "\n",
    "        #return audios, np.array(y_emotion_class), np.array(y_emotion_intensity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"D:/134-1.감정이 태깅된 자유대화 (성인)/01-1.정식개방데이터/Training\"\n",
    "audio_source = \"01.원천데이터\"\n",
    "label_str = \"02.라벨링데이터\"\n",
    "indoor_ = [\"실내\", \"실외\"] \n",
    "indoor_files = glob.glob(os.path.join(path,label_str,indoor_[0], '*.json'))\n",
    "outdoor_files = glob.glob(os.path.join(path,label_str,indoor_[1], '*.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_generator(\n",
    "    lambda: load_segments_from_json(indoor_files + outdoor_files, os.path.join(path,audio_source)),\n",
    "    output_signature=(\n",
    "        tf.TensorSpec(shape=(None,), dtype=tf.float32),\n",
    "        tf.TensorSpec(shape=(), dtype=tf.int32),\n",
    "        tf.TensorSpec(shape=(), dtype=tf.float32)\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(audio_segment, emotion_category, emotion_intensity):\n",
    "    waveform_padded = features_lib.pad_waveform(audio_segment, params)\n",
    "    #_, features = features_lib.waveform_to_log_mel_spectrogram_patches(\n",
    "    #    waveform_padded, params)\n",
    "    #num_patches = tf.shape(features)[1]\n",
    "    #tf.print(tf.shape(features))\n",
    "    #emotion_class_repeated = tf.repeat(emotion_category[tf.newaxis], num_patches, axis=0)\n",
    "    #emotion_intensity_repeated = tf.repeat(emotion_intensity[tf.newaxis], num_patches, axis=0)\n",
    "    labels = {\n",
    "        'emotion_class_output': emotion_category,\n",
    "        'emotion_intensity_output': emotion_intensity\n",
    "    }\n",
    "    #tf.print(tf.shape(emotion_class_repeated), len(labels[\"emotion_class_output\"]))\n",
    "    return audio_segment, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.map(preprocess, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "dataset = dataset.shuffle(buffer_size=1000)\n",
    "batch_size = 1\n",
    "dataset = dataset.padded_batch(\n",
    "    batch_size,\n",
    "    padded_shapes=([None, ], {'emotion_class_output': [], 'emotion_intensity_output': []}),\n",
    "    padding_values=(0.0, {'emotion_class_output': 0, 'emotion_intensity_output': 0.0})\n",
    ")\n",
    "dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction_model(input_shape, num_classes):\n",
    "    \"\"\"Defines the prediction model for emotion classification and intensity regression.\"\"\"\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "    x = layers.Dense(128, activation='relu')(inputs)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    emotion_class_output = layers.Dense(num_classes, activation='softmax', name='emotion_class_output')(x)\n",
    "    emotion_intensity_output = layers.Dense(1, activation='linear', name='emotion_intensity_output')(x)\n",
    "    model = Model(inputs=inputs,  outputs= [emotion_class_output, emotion_intensity_output], name='emotion_recognition_model')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = yamnet_params.Params()\n",
    "\n",
    "embedding_model = yamnet_model.yamnet_embedding_model(params)\n",
    "\n",
    "for layer in embedding_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "num_classes = len(emotion_enc)\n",
    "prediction_net = prediction_model(input_shape=(1024,), num_classes=num_classes)\n",
    "\n",
    "waveform_input = embedding_model.inputs[0]\n",
    "embeddings = embedding_model.outputs[0]\n",
    "predictions = prediction_net(embeddings)\n",
    "#waveform_input = layers.Input(shape=(None,), dtype=tf.float32)\n",
    "#embeddings = embedding_model(waveform_input)\n",
    "#predictions = prediction_net(embeddings)\n",
    "\n",
    "model = Model(inputs=waveform_input, outputs={\"emotion_class_output\": predictions[0],\n",
    "             \"emotion_intensity_output\": predictions[1]}, name='emotion_recognition_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss={\n",
    "        'emotion_class_output': 'sparse_categorical_crossentropy',\n",
    "        'emotion_intensity_output': 'mean_squared_error'\n",
    "    },\n",
    "    metrics={\n",
    "        'emotion_class_output': 'accuracy',\n",
    "        'emotion_intensity_output': 'mae'\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer Name: input_11, Output Shape: [(None,)]\n",
      "Layer Name: tf.compat.v1.shape_10, Output Shape: (1,)\n",
      "Layer Name: tf.__operators__.getitem_10, Output Shape: ()\n",
      "Layer Name: tf.reshape_5, Output Shape: (None, None)\n",
      "Layer Name: tf.compat.v1.shape_11, Output Shape: (2,)\n",
      "Layer Name: tf.__operators__.getitem_11, Output Shape: ()\n",
      "Layer Name: tf.math.subtract_16, Output Shape: ()\n",
      "Layer Name: tf.cast_10, Output Shape: ()\n",
      "Layer Name: tf.math.truediv_5, Output Shape: ()\n",
      "Layer Name: tf.math.ceil_5, Output Shape: ()\n",
      "Layer Name: tf.cast_11, Output Shape: ()\n",
      "Layer Name: tf.math.subtract_15, Output Shape: ()\n",
      "Layer Name: tf.math.multiply_5, Output Shape: ()\n",
      "Layer Name: tf.math.maximum_5, Output Shape: ()\n",
      "Layer Name: tf.math.subtract_17, Output Shape: ()\n",
      "Layer Name: tf.__operators__.add_10, Output Shape: ()\n",
      "Layer Name: tf.compat.v1.pad_5, Output Shape: (None, None)\n",
      "Layer Name: tf.signal.stft_5, Output Shape: (None, None, 257)\n",
      "Layer Name: tf.math.abs_5, Output Shape: (None, None, 257)\n",
      "Layer Name: tf.tensordot_5, Output Shape: (None, None, 64)\n",
      "Layer Name: tf.__operators__.add_11, Output Shape: (None, None, 64)\n",
      "Layer Name: tf.math.log_5, Output Shape: (None, None, 64)\n",
      "Layer Name: tf.signal.frame_5, Output Shape: (None, None, 96, 64)\n",
      "Layer Name: reshape_5, Output Shape: (None, None, 64, 1)\n",
      "Layer Name: layer1/conv, Output Shape: (None, None, 32, 32)\n",
      "Layer Name: layer1/conv/bn, Output Shape: (None, None, 32, 32)\n",
      "Layer Name: layer1/relu, Output Shape: (None, None, 32, 32)\n",
      "Layer Name: layer2/depthwise_conv, Output Shape: (None, None, 32, 32)\n",
      "Layer Name: layer2/depthwise_conv/bn, Output Shape: (None, None, 32, 32)\n",
      "Layer Name: layer2/depthwise_conv/relu, Output Shape: (None, None, 32, 32)\n",
      "Layer Name: layer2/pointwise_conv, Output Shape: (None, None, 32, 64)\n",
      "Layer Name: layer2/pointwise_conv/bn, Output Shape: (None, None, 32, 64)\n",
      "Layer Name: layer2/pointwise_conv/relu, Output Shape: (None, None, 32, 64)\n",
      "Layer Name: layer3/depthwise_conv, Output Shape: (None, None, 16, 64)\n",
      "Layer Name: layer3/depthwise_conv/bn, Output Shape: (None, None, 16, 64)\n",
      "Layer Name: layer3/depthwise_conv/relu, Output Shape: (None, None, 16, 64)\n",
      "Layer Name: layer3/pointwise_conv, Output Shape: (None, None, 16, 128)\n",
      "Layer Name: layer3/pointwise_conv/bn, Output Shape: (None, None, 16, 128)\n",
      "Layer Name: layer3/pointwise_conv/relu, Output Shape: (None, None, 16, 128)\n",
      "Layer Name: layer4/depthwise_conv, Output Shape: (None, None, 16, 128)\n",
      "Layer Name: layer4/depthwise_conv/bn, Output Shape: (None, None, 16, 128)\n",
      "Layer Name: layer4/depthwise_conv/relu, Output Shape: (None, None, 16, 128)\n",
      "Layer Name: layer4/pointwise_conv, Output Shape: (None, None, 16, 128)\n",
      "Layer Name: layer4/pointwise_conv/bn, Output Shape: (None, None, 16, 128)\n",
      "Layer Name: layer4/pointwise_conv/relu, Output Shape: (None, None, 16, 128)\n",
      "Layer Name: layer5/depthwise_conv, Output Shape: (None, None, 8, 128)\n",
      "Layer Name: layer5/depthwise_conv/bn, Output Shape: (None, None, 8, 128)\n",
      "Layer Name: layer5/depthwise_conv/relu, Output Shape: (None, None, 8, 128)\n",
      "Layer Name: layer5/pointwise_conv, Output Shape: (None, None, 8, 256)\n",
      "Layer Name: layer5/pointwise_conv/bn, Output Shape: (None, None, 8, 256)\n",
      "Layer Name: layer5/pointwise_conv/relu, Output Shape: (None, None, 8, 256)\n",
      "Layer Name: layer6/depthwise_conv, Output Shape: (None, None, 8, 256)\n",
      "Layer Name: layer6/depthwise_conv/bn, Output Shape: (None, None, 8, 256)\n",
      "Layer Name: layer6/depthwise_conv/relu, Output Shape: (None, None, 8, 256)\n",
      "Layer Name: layer6/pointwise_conv, Output Shape: (None, None, 8, 256)\n",
      "Layer Name: layer6/pointwise_conv/bn, Output Shape: (None, None, 8, 256)\n",
      "Layer Name: layer6/pointwise_conv/relu, Output Shape: (None, None, 8, 256)\n",
      "Layer Name: layer7/depthwise_conv, Output Shape: (None, None, 4, 256)\n",
      "Layer Name: layer7/depthwise_conv/bn, Output Shape: (None, None, 4, 256)\n",
      "Layer Name: layer7/depthwise_conv/relu, Output Shape: (None, None, 4, 256)\n",
      "Layer Name: layer7/pointwise_conv, Output Shape: (None, None, 4, 512)\n",
      "Layer Name: layer7/pointwise_conv/bn, Output Shape: (None, None, 4, 512)\n",
      "Layer Name: layer7/pointwise_conv/relu, Output Shape: (None, None, 4, 512)\n",
      "Layer Name: layer8/depthwise_conv, Output Shape: (None, None, 4, 512)\n",
      "Layer Name: layer8/depthwise_conv/bn, Output Shape: (None, None, 4, 512)\n",
      "Layer Name: layer8/depthwise_conv/relu, Output Shape: (None, None, 4, 512)\n",
      "Layer Name: layer8/pointwise_conv, Output Shape: (None, None, 4, 512)\n",
      "Layer Name: layer8/pointwise_conv/bn, Output Shape: (None, None, 4, 512)\n",
      "Layer Name: layer8/pointwise_conv/relu, Output Shape: (None, None, 4, 512)\n",
      "Layer Name: layer9/depthwise_conv, Output Shape: (None, None, 4, 512)\n",
      "Layer Name: layer9/depthwise_conv/bn, Output Shape: (None, None, 4, 512)\n",
      "Layer Name: layer9/depthwise_conv/relu, Output Shape: (None, None, 4, 512)\n",
      "Layer Name: layer9/pointwise_conv, Output Shape: (None, None, 4, 512)\n",
      "Layer Name: layer9/pointwise_conv/bn, Output Shape: (None, None, 4, 512)\n",
      "Layer Name: layer9/pointwise_conv/relu, Output Shape: (None, None, 4, 512)\n",
      "Layer Name: layer10/depthwise_conv, Output Shape: (None, None, 4, 512)\n",
      "Layer Name: layer10/depthwise_conv/bn, Output Shape: (None, None, 4, 512)\n",
      "Layer Name: layer10/depthwise_conv/relu, Output Shape: (None, None, 4, 512)\n",
      "Layer Name: layer10/pointwise_conv, Output Shape: (None, None, 4, 512)\n",
      "Layer Name: layer10/pointwise_conv/bn, Output Shape: (None, None, 4, 512)\n",
      "Layer Name: layer10/pointwise_conv/relu, Output Shape: (None, None, 4, 512)\n",
      "Layer Name: layer11/depthwise_conv, Output Shape: (None, None, 4, 512)\n",
      "Layer Name: layer11/depthwise_conv/bn, Output Shape: (None, None, 4, 512)\n",
      "Layer Name: layer11/depthwise_conv/relu, Output Shape: (None, None, 4, 512)\n",
      "Layer Name: layer11/pointwise_conv, Output Shape: (None, None, 4, 512)\n",
      "Layer Name: layer11/pointwise_conv/bn, Output Shape: (None, None, 4, 512)\n",
      "Layer Name: layer11/pointwise_conv/relu, Output Shape: (None, None, 4, 512)\n",
      "Layer Name: layer12/depthwise_conv, Output Shape: (None, None, 4, 512)\n",
      "Layer Name: layer12/depthwise_conv/bn, Output Shape: (None, None, 4, 512)\n",
      "Layer Name: layer12/depthwise_conv/relu, Output Shape: (None, None, 4, 512)\n",
      "Layer Name: layer12/pointwise_conv, Output Shape: (None, None, 4, 512)\n",
      "Layer Name: layer12/pointwise_conv/bn, Output Shape: (None, None, 4, 512)\n",
      "Layer Name: layer12/pointwise_conv/relu, Output Shape: (None, None, 4, 512)\n",
      "Layer Name: layer13/depthwise_conv, Output Shape: (None, None, 2, 512)\n",
      "Layer Name: layer13/depthwise_conv/bn, Output Shape: (None, None, 2, 512)\n",
      "Layer Name: layer13/depthwise_conv/relu, Output Shape: (None, None, 2, 512)\n",
      "Layer Name: layer13/pointwise_conv, Output Shape: (None, None, 2, 1024)\n",
      "Layer Name: layer13/pointwise_conv/bn, Output Shape: (None, None, 2, 1024)\n",
      "Layer Name: layer13/pointwise_conv/relu, Output Shape: (None, None, 2, 1024)\n",
      "Layer Name: layer14/depthwise_conv, Output Shape: (None, None, 2, 1024)\n",
      "Layer Name: layer14/depthwise_conv/bn, Output Shape: (None, None, 2, 1024)\n",
      "Layer Name: layer14/depthwise_conv/relu, Output Shape: (None, None, 2, 1024)\n",
      "Layer Name: layer14/pointwise_conv, Output Shape: (None, None, 2, 1024)\n",
      "Layer Name: layer14/pointwise_conv/bn, Output Shape: (None, None, 2, 1024)\n",
      "Layer Name: layer14/pointwise_conv/relu, Output Shape: (None, None, 2, 1024)\n",
      "Layer Name: embedding_output, Output Shape: (None, 1024)\n",
      "Layer Name: emotion_recognition_model, Output Shape: [(None, 7), (None, 1)]\n"
     ]
    }
   ],
   "source": [
    "for layer in model.layers:\n",
    "    print(f\"Layer Name: {layer.name}, Output Shape: {layer.output_shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:From c:\\Users\\jspark\\miniconda3\\Lib\\site-packages\\tf_keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\jspark\\miniconda3\\Lib\\site-packages\\tf_keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "  43842/Unknown - 4941s 111ms/step - loss: 1.7759 - emotion_recognition_model_loss: 1.4653 - emotion_recognition_model_1_loss: 0.3105 - emotion_recognition_model_accuracy: 0.4322 - emotion_recognition_model_1_mae: 0.4188"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\jspark\\miniconda3\\Lib\\site-packages\\tf_keras\\src\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\jspark\\miniconda3\\Lib\\site-packages\\tf_keras\\src\\engine\\training.py:1804\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1796\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1797\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1798\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1801\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1802\u001b[0m ):\n\u001b[0;32m   1803\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1804\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1805\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1806\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Users\\jspark\\miniconda3\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\jspark\\miniconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\jspark\\miniconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:869\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    866\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    867\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    868\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 869\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    870\u001b[0m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_config\u001b[49m\n\u001b[0;32m    871\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    872\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    873\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    874\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    875\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32mc:\\Users\\jspark\\miniconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[1;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[0;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\jspark\\miniconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[0;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1324\u001b[0m     args,\n\u001b[0;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1326\u001b[0m     executing_eagerly)\n\u001b[0;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\jspark\\miniconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[1;32mc:\\Users\\jspark\\miniconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[0;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[0;32m    261\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\jspark\\miniconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\context.py:1552\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1550\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1551\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1552\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1553\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1554\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1555\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1556\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1557\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1558\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1560\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1561\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1562\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1566\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1567\u001b[0m   )\n",
      "File \u001b[1;32mc:\\Users\\jspark\\miniconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(dataset, epochs=10, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('10epoch.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
