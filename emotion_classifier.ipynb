{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division, print_function\n",
    "\n",
    "import sys\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "import numpy as np\n",
    "import resampy\n",
    "import soundfile as sf\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model, layers, optimizers\n",
    "\n",
    "\n",
    "import params as yamnet_params\n",
    "import yamnet as yamnet_model\n",
    "import features as features_lib\n",
    "from random import shuffle\n",
    "\n",
    "import librosa\n",
    "import json\n",
    "import glob\n",
    "\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "intense = {\"약함\" : 0.,\"보통\":1.,\"강함\":2.}\n",
    "emotion_enc = {\"기쁨\" : 0, \"사랑스러움\" : 1, \"두려움\" : 2, \"화남\" : 3, \"슬픔\" : 4, \"놀라움\" : 5, \"없음\" : 6}\n",
    "emotion_dec = { 0 : \"기쁨\", 1 : \"사랑스러움\", 2 : \"두려움\", 3 : \"화남\", 4 : \"슬픔\", 5 : \"놀라움\", 6 : \"없음\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_split_data_from_json(root_path):\n",
    "    label_path = os.path.join(root_path, \"label\")\n",
    "    data_path = os.path.join(root_path, \"data\")\n",
    "    sr = 16000\n",
    "    json_list = glob.glob(os.path.join(label_path,'*.json'))[:10]\n",
    "    for path in json_list:\n",
    "        with open(path, 'r') as f:\n",
    "            data = json.load(f)\n",
    "        \n",
    "        wav_name = os.path.join(data_path, os.path.basename(path).split(\".\")[0] + \".wav\")\n",
    "        audio, _ = librosa.load(wav_name, sr=sr)\n",
    "\n",
    "        text = data['text']\n",
    "        emotion_category = data[\"emotion_category\"]\n",
    "        emotion_intense = data[\"emotion_intense\"]\n",
    "        \n",
    "        yield np.array(audio), emotion_category, emotion_intense\n",
    "\n",
    "        #return audios, np.array(y_emotion_class), np.array(y_emotion_intensity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = \"D:/emotion_split/train\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_generator(\n",
    "    lambda: load_split_data_from_json(train_path),\n",
    "    output_signature=(\n",
    "        tf.TensorSpec(shape=(None,), dtype=tf.float32),\n",
    "        tf.TensorSpec(shape=(), dtype=tf.int32),\n",
    "        tf.TensorSpec(shape=(), dtype=tf.float32)\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(audio_segment, emotion_category, emotion_intensity):\n",
    "    labels = {\n",
    "        'emotion_class_output': emotion_category,\n",
    "        'emotion_intensity_output': emotion_intensity\n",
    "    }\n",
    "    return audio_segment, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.map(preprocess, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "dataset = dataset.shuffle(buffer_size=100)\n",
    "batch_size = 16\n",
    "\n",
    "dataset = dataset.padded_batch(\n",
    "    batch_size,\n",
    "    padded_shapes=([None, ], {'emotion_class_output': [], 'emotion_intensity_output': []}),\n",
    "    padding_values=(0.0, {'emotion_class_output': 0, 'emotion_intensity_output': 0.0})\n",
    ")\n",
    "dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction_model(input_shape, num_classes):\n",
    "    \"\"\"Defines the prediction model for emotion classification and intensity regression.\"\"\"\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "    x = layers.Dense(128, activation='relu')(inputs)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    emotion_class_output = layers.Dense(num_classes, activation='softmax', name='emotion_class_output')(x)\n",
    "    emotion_intensity_output = layers.Dense(1, activation='linear', name='emotion_intensity_output')(x)\n",
    "    model = Model(inputs=inputs,  outputs= [emotion_class_output, emotion_intensity_output], name='emotion_recognition_model')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = yamnet_params.Params()\n",
    "\n",
    "embedding_model = yamnet_model.yamnet_embedding_model(params, \"yamnet.h5\")\n",
    "\n",
    "for layer in embedding_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "num_classes = len(emotion_enc)\n",
    "prediction_net = prediction_model(input_shape=(1024,), num_classes=num_classes)\n",
    "\n",
    "waveform_input = embedding_model.inputs[0]\n",
    "embeddings = embedding_model.outputs[0]\n",
    "#waveform_input = layers.Input(shape=(None,), dtype=tf.float32, name='waveform_input')\n",
    "#embeddings = embedding_model(waveform_input)\n",
    "predictions = prediction_net(embeddings)\n",
    "\n",
    "model = Model(inputs=waveform_input, outputs={\"emotion_class_output\": predictions[0],\n",
    "             \"emotion_intensity_output\": predictions[1]}, name='emotion_recognition_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SaveModelAtEpochEnd(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, save_dir):\n",
    "        super(SaveModelAtEpochEnd, self).__init__()\n",
    "        self.save_dir = save_dir\n",
    "        if not os.path.exists(self.save_dir):\n",
    "            os.makedirs(self.save_dir)\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        epoch_num = epoch + 1\n",
    "        save_path = os.path.join(self.save_dir, f'epoch_{epoch_num:02d}')\n",
    "        os.makedirs(save_path, exist_ok=True)\n",
    "        tf.saved_model.save(self.model, save_path)\n",
    "        print(f'\\nSaved model at epoch {epoch_num} to {save_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 5\n",
    "\n",
    "lr_schedule = optimizers.schedules.CosineDecay(\n",
    "    initial_learning_rate=0.01,\n",
    "    decay_steps=epoch\n",
    ")\n",
    "\n",
    "optimizer = optimizers.Adam(lr_schedule)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=optimizer\n",
    "    loss={\n",
    "        'emotion_class_output': 'sparse_categorical_crossentropy',\n",
    "        'emotion_intensity_output': 'mean_squared_error'\n",
    "    },\n",
    "    metrics={\n",
    "        'emotion_class_output': 'accuracy',\n",
    "        'emotion_intensity_output': 'mae'\n",
    "    },\n",
    "    run_eagerly=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(dataset, epochs=epoch, verbose=1,callbacks=[save_callback])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yamnet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
